---
layout: post
comments: true
title:  "Approaches to Web Scrapping with Node.js - API Calls - Part I"
excerpt: "In this blog post I describe how to do API calls to get data from web pages."
date:   2018-03-05 12:00:00
published:   false
---

# Approaches to Web Scrapping with Node.js

Why Web Scrapping?
What is the importance of it related to Big Data topic?
What will be explained in this blog post?

In this series, I'll describe three different approaches and when to use them.


## API calls

When to use:

Pros: Fast, data is already parsed (usually better quality).

Cons: Complexity of undestanding how the API Works, Can break on API updates

Most of web pages uses some kind of antiforgery tokens/CSFR tokens or sessions. Because of this, we ussually need to obtain the page before doing any post to the site for getting the Cookies and/or response headers that may contain these tokens.

Use of the browser developer tools to inspect network requests. We should keep an eye for session cookies and especial response/request headers.

User Agent, Referrer


Example

```js
const bluebird = require("bluebird");
const rq = require("request");
const URL = require("url").URL;
const jar = rq.jar();
const request = bluebird.promisify(
  rq.defaults({ jar, timeout: 60000, gzip: true })
);

const headers = {
  "Content-Type": "application/json;charset=UTF-8",
  "User-Agent":
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36",
  "Cache-Control": "no-cache",
  "Pragma": "no-cache",
  "Accept-Encoding": "gzip, deflate, br",
  "Accept-Language": "en-US,en;q=0.8,pt-BR;q=0.6,pt;q=0.4",
  "Accept": "application/json, text/plain, */*"
};

function get(url) {
  return request({ url, headers });
}

function postJson(url, json) {
  return request({
    method: "POST",
    headers,
    url,
    json
  });
}

function postForm(url, form) {
  const origin = new URL(url).origin;
  const modifiedHeaders = Object.assign({}, headers, {
    Referer: origin,
    "X-CSRFToken": jar.getCookies(origin).find(a => a.key === "csrftoken").value
  });
  return request({
    method: "POST",
    headers: modifiedHeaders,
    url,
    form
  });
}

(async () => {

  // Authenticate to the instagram
  const username = "username";
  const password = "password";
  // First do a request to get Cookies
  await get("https://www.instagram.com/");
  const response = await postForm(
    "https://www.instagram.com/accounts/login/ajax/",
    {
      username,
      password
    }
  );
  const result = JSON.parse(response.body);
  if (!result.authenticated) {
    throw new Error("Authentication failed");
  }
  console.log("Authentication succeeded");

  // Get images from a given tag name
  const tagName = "godafoss";
  const response = await get(
    `https://www.instagram.com/explore/tags/${tagName}/?__a=1`
  );
  const result = JSON.parse(response.body);
  const nodes = result.graphql.hashtag.edge_hashtag_to_media.edges.map(
    a => a.node
  );
  console.log(nodes.map(a => `${a.id}: '${a.display_url}'`).join("\n"));
})().catch(error => console.error(error));
```

## What's next?

- Simple HTML parsing with cheerio - Part II
- Parsing HTML and executing JavaScript with Chrome Headless Browser - Part III
